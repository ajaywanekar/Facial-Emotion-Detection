{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn                   #for sequence api in torch\n",
        "from torch.utils.data import DataLoader #for loading images\n",
        "import numpy as np                      #just in case if you need numpy arrays\n",
        "import torchvision.transforms as T      #Used for data preprocessing and converting images to tensors\n",
        "import torchvision.datasets as dset\n",
        "import torch.optim as optim             #For using the desired parameter update\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "dtype = torch.float32\n",
        "print(\"Using device: \",device)\n"
      ],
      "metadata": {
        "id": "w2LGGGgHxT4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/MyDrive/FER_Dataset.zip\""
      ],
      "metadata": {
        "id": "233ALkSsUKVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading and pre-processing"
      ],
      "metadata": {
        "id": "CxT2fcNjuiKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = T.Compose([T.RandomHorizontalFlip(),T.ToTensor()])\n",
        "#Training\n",
        "train_data = ImageFolder(\"/content/images/images/train\",transform=transform)\n",
        "loaded_train = DataLoader(train_data,batch_size=64,shuffle=True)\n",
        "#Validation\n",
        "validation_data = ImageFolder (\"/content/images/images/validation\",transform=transform)\n",
        "loaded_validation = DataLoader(validation_data,batch_size=64,shuffle=False)\n",
        "\n",
        "loss_history = []\n",
        "validation_acc = []\n",
        "training_acc = []"
      ],
      "metadata": {
        "id": "GarO-yqCsZqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the image"
      ],
      "metadata": {
        "id": "4v80DfNNJ0DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random                   #For selecting random element from list\n",
        "\n",
        "dataiter = iter(loaded_train)   #The iter() function in python represents the iterator similar to c++ iterators\n",
        "images, labels = next(dataiter) #The next() method retrieves the object\n",
        "expression = {0:\"angry\",1:\"disgust\",2:\"fear\",3:\"happy\",4:\"neutral\",5:\"sad\",6:\"surprise\"} #Create a dictionary for mapping accordingly\n",
        "random_idx = random.sample(range(0,64),1)[0]     #Selects a random single number from 0-64\n",
        "print(\"Target label: \",expression[int(labels[random_idx].numpy())])  #Converting it to numpy from tensor to fetch the label\n",
        "plt.imshow(np.transpose(images[random_idx].numpy(), (1, 2, 0)))"
      ],
      "metadata": {
        "id": "qFoigm0IJ3bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a method for predicting validation accuracy¶"
      ],
      "metadata": {
        "id": "a-xQsExaKF1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy_part(loader, model):\n",
        "    print('Checking accuracy on validation set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "metadata": {
        "id": "ul_Z4wfVJ_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a method for predicting validation accuracy"
      ],
      "metadata": {
        "id": "yF_VW8NtL7lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy_part(loader, model):\n",
        "    print('Checking accuracy on validation set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "metadata": {
        "id": "6uGXOhmeL88e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "2xHk16ThgFef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_part(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        print(\"epoch: \",e+1)\n",
        "        for t, (x, y) in enumerate(loaded_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part(loaded_validation, model)\n",
        "                print()"
      ],
      "metadata": {
        "id": "mfcrIr23gFEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building our neural network"
      ],
      "metadata": {
        "id": "Jl-mLOoQgZNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "#First architecture #3,32,32\n",
        "conv1 = nn.Sequential(\n",
        "    nn.Conv2d(3,512,kernel_size=(3,3),bias=True,padding=1), #512,48,48\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))  #Sampling image to half  512,24,24\n",
        ")\n",
        "conv2 = nn.Sequential(\n",
        "    nn.Conv2d(512,128,kernel_size=(3,3),padding=1,bias=True), #128,24,24\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))         #128,12,12\n",
        ")\n",
        "conv3 = nn.Sequential(\n",
        "    nn.Conv2d(128,64,kernel_size=(3,3),bias=True,padding=1), #64,12,12\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))   #64,6,6\n",
        ")\n",
        "conv4 = nn.Sequential(\n",
        "    nn.Conv2d(64,256,kernel_size=(3,3),bias=True,padding=1), #64,6,6\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))   #256,3,3\n",
        ")\n",
        "fc = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256*3*3,7),\n",
        ")\n",
        "model = nn.Sequential(\n",
        "    conv1,\n",
        "    conv2,\n",
        "    conv3,\n",
        "    conv4,\n",
        "    fc\n",
        ")\n",
        "learning_rate=0.0001\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "train_part(model, optimizer, epochs=30)"
      ],
      "metadata": {
        "id": "TlCpjlGrgbyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best performance:"
      ],
      "metadata": {
        "id": "KJYK_kLKgh7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Best model\n",
        "best_model = model\n",
        "check_accuracy_part(loaded_validation,best_model)"
      ],
      "metadata": {
        "id": "f81wFJQsgruc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing our model with sample images:¶"
      ],
      "metadata": {
        "id": "28c5wGOEg4tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def check_accuracy_test(x,y,model):\n",
        "#   num_samples = 0\n",
        "#   num_correct = 0\n",
        "#   loss = None\n",
        "#   model.eval()    #turning drop-out/batch norm layer from training to test mode\n",
        "#   with torch.no_grad():\n",
        "#     x = x.to(device=device,dtype=dtype)\n",
        "#     y = y.to(device=device,dtype=torch.long)\n",
        "#     scores = model(x)\n",
        "#     _,preds = scores.max(1)\n",
        "#     return preds\n",
        "\n",
        "#     expression = {0:\"angry\",1:\"fear\",2:\"happy\",3:\"sad\",4:\"surprise\"} #Create a dictionary for mapping accordingly\n",
        "\n",
        "# transform = T.Compose([T.ToTensor()])\n",
        "# test_data = dset.ImageFolder(\"/content/drive/MyDrive/images.colab\",transform=transform)\n",
        "# loaded_test = DataLoader(test_data,batch_size=6,shuffle=False)\n",
        "\n",
        "# dataiter = iter(loaded_test)   #The iter() function in python represents the iterator similar to c++ iterators\n",
        "# images, labels = next(dataiter) #The next() method retrieves the object\n",
        "\n",
        "# random_idx = random.sample(range(0,5),1)[0]\n",
        "\n",
        "# image = torch.reshape(images[random_idx],(1,3,48,48))\n",
        "# predicted_idx = check_accuracy_test(image,labels[random_idx],best_model)\n",
        "# print(\"Predicted label: \",expression[predicted_idx.item()])\n",
        "# print(\"Correct label: \",expression[int(labels[random_idx].numpy())])  #Converting it to numpy from tensor to fetch the label\n",
        "# image = torch.reshape(image,(3,48,48))\n",
        "# plt.imshow(np.transpose(image.numpy(), (1, 2, 0)))\n"
      ],
      "metadata": {
        "id": "UvbzEtIIg9As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model, 'model_2.pth')"
      ],
      "metadata": {
        "id": "znvFy7jm_Wns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "TvH1UwtgVx15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMyew0D9_FrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}